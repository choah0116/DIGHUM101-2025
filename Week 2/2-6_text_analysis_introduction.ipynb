{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><b>DIGHUM101</b></center>\n",
    "<center>2-6: Text Analysis: Introduction</center>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fast review\n",
    "\n",
    "1. What is a data frame? \n",
    "2. What methods and other syntax can be used to subset rows and columns?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning objectives\n",
    "\n",
    "1. Download a .txt file from Project Gutenberg and import it into Python\n",
    "2. Quick walkthrough of Hathi Trust Research Center (HTRC) resources\n",
    "3. Learn the basics of text preprocessing: \n",
    "    - Tokenization\n",
    "    - Punctuation removal\n",
    "    - Count words, unique words, and word frequencies\n",
    "    - Stop word removal\n",
    "    - Stemming/lemmatization\n",
    "    - Part of speech tagging\n",
    "    - Quick introduction to n-grams, skip-grams, and BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Module to remove punctuation from string library\n",
    "from string import punctuation\n",
    "print(punctuation)\n",
    "print(len(punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Module to count word frequencies\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Module to help us remove stopwords\n",
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"averaged_perceptron_tagger\") # a pre-trained part-of-speech (POS) tagger\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install spaCy and trained model downloaded.\n",
    "# install spacy\n",
    "#!pip install spacy\n",
    "\n",
    "# Download a trained English model (small)\n",
    "# !python -m spacy download en_core_web_sm \n",
    "\n",
    "# Download the large model as well\n",
    "# !python -m spacy download en_core_web_lg\n",
    "# import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Gutenberg\n",
    "\n",
    "[Project Gutenberg](https://www.gutenberg.org/) has more than 60,000 texts for you to download. Be sure to check out their [Terms of Use](https://www.gutenberg.org/wiki/Gutenberg:Terms_of_Use). You can find many .txt files here that are in the public domain. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try it! Search for a book, download it, copy it to your working directory, and import it.\n",
    "\n",
    "## YOUR CODE HERE\n",
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../Data/\") # CHANGE PATH HERE\n",
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## HOW TO IMPORT dracula.txt?\n",
    "dracula = open(\"dracula.txt\").read()\n",
    "print(dracula[501:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Hathi Trust Research Center (HTRC)\n",
    "\n",
    "Check out the [HTRC](https://www.hathitrust.org/) and learn about their many [collections tools](https://www.hathitrust.org/htrc_collections_tools) and the [Python library](https://github.com/htrc/htrc-feature-reader) to connect to the API. The [Analytics](https://analytics.hathitrust.org/) website gives you access to many canned features if you don't want to mess with the Python code. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Preprocessing: Strings in depth\n",
    "\n",
    "Text preprocessing is an essential first step to coding and understanding machine learning algorithms. For machine learning portions of this course, we will focus on [bag of words](https://en.wikipedia.org/wiki/Bag-of-words_model) models, namely [document-term](https://en.wikipedia.org/wiki/Document-term_matrix) and [term frequency-inverse document frequency](https://en.wikipedia.org/wiki/Tf%E2%80%93idf) matrices from the [sklearn library](https://scikit-learn.org/stable/).\n",
    "\n",
    "Text preprocessing/pattern matching can be further enhanced through use of [regular expressions](https://docs.python.org/2/library/re.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "\n",
      "In the fullness of the years, like it or not,\n",
      "a luminous mist surrounds me, unvarying, \n",
      "that breaks things down into a single thing,\n",
      "colorless, formless. Almost into a thought. \n",
      "The elemental, vast night and the day\n",
      "teeming with people have become that fog\n",
      "of constant, tentative light that does not flag,\n",
      "\n",
      "and lies in wait at dawn. I longed to see\n",
      "just once a human face. Unknown to me\n",
      "the closed encyclopedia, the sweet play\n",
      "in volumes I can do no more than hold, \n",
      "the tiny soaring birds, the moons of gold.\n",
      "Others have the world, for better or worse; \n",
      "I have this half-dark, and the toil of verse.\n"
     ]
    }
   ],
   "source": [
    "borges = '''In the fullness of the years, like it or not,\n",
    "a luminous mist surrounds me, unvarying, \n",
    "that breaks things down into a single thing,\n",
    "colorless, formless. Almost into a thought. \n",
    "The elemental, vast night and the day\n",
    "teeming with people have become that fog\n",
    "of constant, tentative light that does not flag,\n",
    "\n",
    "and lies in wait at dawn. I longed to see\n",
    "just once a human face. Unknown to me\n",
    "the closed encyclopedia, the sweet play\n",
    "in volumes I can do no more than hold, \n",
    "the tiny soaring birds, the moons of gold.\n",
    "Others have the world, for better or worse; \n",
    "I have this half-dark, and the toil of verse.'''\n",
    "\n",
    "\n",
    "print(type(borges))\n",
    "print() # this just prints a new line\n",
    "print(borges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What do the triple quotes do in the assignment of borges above?\n",
    "\n",
    "# Also, make a copy to preserve the original borges variable\n",
    "poem = borges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization\n",
    "\n",
    "Tokenization is the process of splitting text into _something_ - often words. Each word is called a \"token\" and a word such as \"the\" might adhere to multiple tokens of \"the\" within a text based on its capitalization, punctuation, etc.\n",
    "\n",
    "The `.split()` method allows us to split the text based on some sort of separator. The default is blank and will split on the blank spaces between words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['In', 'the', 'fullness', 'of', 'the', 'years,', 'like', 'it', 'or', 'not,', 'a', 'luminous', 'mist', 'surrounds', 'me,', 'unvarying,', 'that', 'breaks', 'things', 'down', 'into', 'a', 'single', 'thing,', 'colorless,', 'formless.', 'Almost', 'into', 'a', 'thought.', 'The', 'elemental,', 'vast', 'night', 'and', 'the', 'day', 'teeming', 'with', 'people', 'have', 'become', 'that', 'fog', 'of', 'constant,', 'tentative', 'light', 'that', 'does', 'not', 'flag,', 'and', 'lies', 'in', 'wait', 'at', 'dawn.', 'I', 'longed', 'to', 'see', 'just', 'once', 'a', 'human', 'face.', 'Unknown', 'to', 'me', 'the', 'closed', 'encyclopedia,', 'the', 'sweet', 'play', 'in', 'volumes', 'I', 'can', 'do', 'no', 'more', 'than', 'hold,', 'the', 'tiny', 'soaring', 'birds,', 'the', 'moons', 'of', 'gold.', 'Others', 'have', 'the', 'world,', 'for', 'better', 'or', 'worse;', 'I', 'have', 'this', 'half-dark,', 'and', 'the', 'toil', 'of', 'verse.']\n"
     ]
    }
   ],
   "source": [
    "# Split the string into a list of strings (single words)\n",
    "print(poem.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count words\n",
    "\n",
    "Jump in! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "600"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many characters in poem?\n",
    "len(poem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many words?\n",
    "len(poem.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many lines?\n",
    "len(poem.split(\"\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many periods? \n",
    "# Should this be equal to the number of sentences in the cell below?\n",
    "poem.count(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poem.split(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ... but how many sentences? Why is this different from the number of periods?\n",
    "len(poem.split(\".\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many stanzas?\n",
    "len(poem.split(\"\\n\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# At which index does the word \"me\" first appear?\n",
    "# .find() is \"forward search\"\n",
    "poem.find(\"me\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'me'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poem[72:74]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# .index works as well\n",
    "poem.index(\"me\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note that .find does not throw an error when an element is not found (but .index does)\n",
    "poem.find(\"kangaroo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "434"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# At which index does the word \"me\" last appear?\n",
    "# .rfind() starts at the highest index and works in reverse\n",
    "poem.rfind(\"me\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count _unique_ words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many unique words?\n",
    "# \"Casting\" our list into a set\n",
    "len(set(poem.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['In', 'the', 'fullness', 'of', 'the', 'years,', 'like', 'it', 'or', 'not,', 'a', 'luminous', 'mist', 'surrounds', 'me,', 'unvarying,', 'that', 'breaks', 'things', 'down', 'into', 'a', 'single', 'thing,', 'colorless,', 'formless.', 'Almost', 'into', 'a', 'thought.', 'The', 'elemental,', 'vast', 'night', 'and', 'the', 'day', 'teeming', 'with', 'people', 'have', 'become', 'that', 'fog', 'of', 'constant,', 'tentative', 'light', 'that', 'does', 'not', 'flag,', 'and', 'lies', 'in', 'wait', 'at', 'dawn.', 'I', 'longed', 'to', 'see', 'just', 'once', 'a', 'human', 'face.', 'Unknown', 'to', 'me', 'the', 'closed', 'encyclopedia,', 'the', 'sweet', 'play', 'in', 'volumes', 'I', 'can', 'do', 'no', 'more', 'than', 'hold,', 'the', 'tiny', 'soaring', 'birds,', 'the', 'moons', 'of', 'gold.', 'Others', 'have', 'the', 'world,', 'for', 'better', 'or', 'worse;', 'I', 'have', 'this', 'half-dark,', 'and', 'the', 'toil', 'of', 'verse.']\n"
     ]
    }
   ],
   "source": [
    "poem_list = poem.split()\n",
    "print(poem_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In\n",
      "the\n",
      "fullness\n",
      "of\n",
      "the\n",
      "years,\n",
      "like\n",
      "it\n",
      "or\n",
      "not,\n",
      "a\n",
      "luminous\n",
      "mist\n",
      "surrounds\n",
      "me,\n",
      "unvarying,\n",
      "that\n",
      "breaks\n",
      "things\n",
      "down\n",
      "into\n",
      "a\n",
      "single\n",
      "thing,\n",
      "colorless,\n",
      "formless.\n",
      "Almost\n",
      "into\n",
      "a\n",
      "thought.\n",
      "The\n",
      "elemental,\n",
      "vast\n",
      "night\n",
      "and\n",
      "the\n",
      "day\n",
      "teeming\n",
      "with\n",
      "people\n",
      "have\n",
      "become\n",
      "that\n",
      "fog\n",
      "of\n",
      "constant,\n",
      "tentative\n",
      "light\n",
      "that\n",
      "does\n",
      "not\n",
      "flag,\n",
      "and\n",
      "lies\n",
      "in\n",
      "wait\n",
      "at\n",
      "dawn.\n",
      "I\n",
      "longed\n",
      "to\n",
      "see\n",
      "just\n",
      "once\n",
      "a\n",
      "human\n",
      "face.\n",
      "Unknown\n",
      "to\n",
      "me\n",
      "the\n",
      "closed\n",
      "encyclopedia,\n",
      "the\n",
      "sweet\n",
      "play\n",
      "in\n",
      "volumes\n",
      "I\n",
      "can\n",
      "do\n",
      "no\n",
      "more\n",
      "than\n",
      "hold,\n",
      "the\n",
      "tiny\n",
      "soaring\n",
      "birds,\n",
      "the\n",
      "moons\n",
      "of\n",
      "gold.\n",
      "Others\n",
      "have\n",
      "the\n",
      "world,\n",
      "for\n",
      "better\n",
      "or\n",
      "worse;\n",
      "I\n",
      "have\n",
      "this\n",
      "half-dark,\n",
      "and\n",
      "the\n",
      "toil\n",
      "of\n",
      "verse.\n"
     ]
    }
   ],
   "source": [
    "for word in poem_list:\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'breaks', 'sweet', 'closed', 'me', 'just', 'unvarying,', 'mist', 'In', 'in', 'down', 'encyclopedia,', 'than', 'colorless,', 'lies', 'or', 'world,', 'and', 'with', 'toil', 'teeming', 'things', 'people', 'can', 'night', 'human', 'become', 'it', 'tiny', 'does', 'light', 'this', 'to', 'hold,', 'elemental,', 'for', 'flag,', 'longed', 'The', 'a', 'the', 'single', 'soaring', 'worse;', 'once', 'more', 'into', 'of', 'at', 'I', 'like', 'see', 'not,', 'better', 'formless.', 'birds,', 'not', 'thought.', 'volumes', 'verse.', 'face.', 'do', 'years,', 'fullness', 'moons', 'no', 'vast', 'Unknown', 'tentative', 'Almost', 'dawn.', 'Others', 'me,', 'wait', 'that', 'fog', 'constant,', 'thing,', 'have', 'half-dark,', 'gold.', 'day', 'play', 'luminous', 'surrounds'}\n"
     ]
    }
   ],
   "source": [
    "poem_set = set(poem_list)\n",
    "print(poem_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "breaks\n",
      "sweet\n",
      "closed\n",
      "me\n",
      "just\n",
      "unvarying,\n",
      "mist\n",
      "In\n",
      "in\n",
      "down\n",
      "encyclopedia,\n",
      "than\n",
      "colorless,\n",
      "lies\n",
      "or\n",
      "world,\n",
      "and\n",
      "with\n",
      "toil\n",
      "teeming\n",
      "things\n",
      "people\n",
      "can\n",
      "night\n",
      "human\n",
      "become\n",
      "it\n",
      "tiny\n",
      "does\n",
      "light\n",
      "this\n",
      "to\n",
      "hold,\n",
      "elemental,\n",
      "for\n",
      "flag,\n",
      "longed\n",
      "The\n",
      "a\n",
      "the\n",
      "single\n",
      "soaring\n",
      "worse;\n",
      "once\n",
      "more\n",
      "into\n",
      "of\n",
      "at\n",
      "I\n",
      "like\n",
      "see\n",
      "not,\n",
      "better\n",
      "formless.\n",
      "birds,\n",
      "not\n",
      "thought.\n",
      "volumes\n",
      "verse.\n",
      "face.\n",
      "do\n",
      "years,\n",
      "fullness\n",
      "moons\n",
      "no\n",
      "vast\n",
      "Unknown\n",
      "tentative\n",
      "Almost\n",
      "dawn.\n",
      "Others\n",
      "me,\n",
      "wait\n",
      "that\n",
      "fog\n",
      "constant,\n",
      "thing,\n",
      "have\n",
      "half-dark,\n",
      "gold.\n",
      "day\n",
      "play\n",
      "luminous\n",
      "surrounds\n"
     ]
    }
   ],
   "source": [
    "for word in poem_set:\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Why two less unique words when we convert all the text to lower?\n",
    "len(set(poem.lower().split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the unique words\n",
    "print(set(poem.lower().split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What type of data structure is this? \n",
    "type(set(poem.lower().split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Why is this different from .lower()?\n",
    "len(set(poem.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Punctuation removal \n",
    "\n",
    "Remember how we imported that nice string of English punctuation in the first cell of this notebook? We could manually remove all of the punctuation using the .replace method, but this would get old fast!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many characters\n",
    "len(punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace periods with nothing\n",
    "del_periods = poem.replace(\".\", \"\")\n",
    "del_periods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But, what if you have tons of text and don't know exactly what punctuation is present? A quick comprehension can help us remove all the punctuation from dirty, i.e. !\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For loop\n",
    "for char in punctuation:\n",
    "    poem = poem.lower().replace(char, \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in the fullness of the years like it or not\n",
      "a luminous mist surrounds me unvarying \n",
      "that breaks things down into a single thing\n",
      "colorless formless almost into a thought \n",
      "the elemental vast night and the day\n",
      "teeming with people have become that fog\n",
      "of constant tentative light that does not flag\n",
      "\n",
      "and lies in wait at dawn i longed to see\n",
      "just once a human face unknown to me\n",
      "the closed encyclopedia the sweet play\n",
      "in volumes i can do no more than hold \n",
      "the tiny soaring birds the moons of gold\n",
      "others have the world for better or worse \n",
      "i have this halfdark and the toil of verse\n"
     ]
    }
   ],
   "source": [
    "# Punctuation is gone! \n",
    "print(poem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count word frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize poem into single words\n",
    "tokens = poem.split()\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the ten most common words (stopwords included)\n",
    "freq = Counter(tokens)\n",
    "freq.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stop word removal\n",
    "\n",
    "[Stop words](https://en.wikipedia.org/wiki/Stop_words) are the most common words in a language, and may or may not add information about the content of the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = stopwords.words(\"english\")\n",
    "print(stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the same as the following:\n",
    "no_stops = []\n",
    "for word in tokens:\n",
    "    if word not in stopwords.words('english'):\n",
    "        no_stops.append(word)\n",
    "print(no_stops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq2 = Counter(no_stops)\n",
    "freq2.most_common(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dighum101",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
